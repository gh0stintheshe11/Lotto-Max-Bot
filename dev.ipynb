{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the lottery_results_final.json file\n",
    "import json\n",
    "\n",
    "with open('lottery_results_final.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis based on 560 draws:\n",
      "\n",
      "Top 20 Most Frequent Numbers:\n",
      "Number | Times Drawn | Probability\n",
      "-----------------------------------\n",
      "19 |          94 |  16.79%\n",
      "46 |          94 |  16.79%\n",
      "32 |          90 |  16.07%\n",
      "36 |          89 |  15.89%\n",
      " 7 |          88 |  15.71%\n",
      "26 |          88 |  15.71%\n",
      "28 |          88 |  15.71%\n",
      "22 |          87 |  15.54%\n",
      "38 |          87 |  15.54%\n",
      "30 |          86 |  15.36%\n",
      " 2 |          85 |  15.18%\n",
      "40 |          85 |  15.18%\n",
      "25 |          84 |  15.00%\n",
      " 9 |          83 |  14.82%\n",
      "31 |          83 |  14.82%\n",
      " 5 |          82 |  14.64%\n",
      "18 |          82 |  14.64%\n",
      " 4 |          82 |  14.64%\n",
      "39 |          82 |  14.64%\n",
      " 1 |          81 |  14.46%\n",
      "\n",
      "Recommended 7 numbers based on historical frequency:\n",
      "[7, 19, 26, 28, 32, 36, 46]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_winning_numbers():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('lottery_results.csv')\n",
    "    \n",
    "    # Filter for dates after July 2019 (RNG era)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'] >= '2019-07-01']\n",
    "    \n",
    "    # Combine all main numbers into a single list\n",
    "    all_numbers = []\n",
    "    for i in range(1, 8):  # 7 main numbers\n",
    "        column = f'Main Numbers {i}'\n",
    "        # Convert to integers and add to list\n",
    "        numbers = df[column].astype(str).str.strip().astype(int).tolist()\n",
    "        all_numbers.extend(numbers)\n",
    "    \n",
    "    # Count frequency of each number\n",
    "    number_counts = Counter(all_numbers)\n",
    "    \n",
    "    # Get the total number of draws\n",
    "    total_draws = len(df)\n",
    "    \n",
    "    # Calculate probability for each number\n",
    "    probabilities = {\n",
    "        num: {\n",
    "            'count': count,\n",
    "            'probability': (count / total_draws) * 100\n",
    "        }\n",
    "        for num, count in number_counts.items()\n",
    "    }\n",
    "    \n",
    "    # Sort by frequency, highest to lowest\n",
    "    sorted_numbers = sorted(probabilities.items(), key=lambda x: x[1]['count'], reverse=True)\n",
    "    \n",
    "    print(f\"\\nAnalysis based on {total_draws} draws:\\n\")\n",
    "    print(\"Top 20 Most Frequent Numbers:\")\n",
    "    print(\"Number | Times Drawn | Probability\")\n",
    "    print(\"-\" * 35)\n",
    "    for num, stats in sorted_numbers[:20]:\n",
    "        print(f\"{num:2d} | {stats['count']:11d} | {stats['probability']:6.2f}%\")\n",
    "    \n",
    "    print(\"\\nRecommended 7 numbers based on historical frequency:\")\n",
    "    recommended = [num for num, _ in sorted_numbers[:7]]\n",
    "    print(sorted(recommended))\n",
    "\n",
    "analyze_winning_numbers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis based on 560 draws:\n",
      "\n",
      "\n",
      "Most Common Pairs of Numbers:\n",
      "Pair | Times Drawn | Probability\n",
      "-----------------------------------\n",
      "(22, 46)        |          21 |   3.75%\n",
      "(30, 37)        |          19 |   3.39%\n",
      "(7, 18)         |          19 |   3.39%\n",
      "(19, 46)        |          19 |   3.39%\n",
      "(26, 28)        |          19 |   3.39%\n",
      "(4, 44)         |          19 |   3.39%\n",
      "(3, 19)         |          18 |   3.21%\n",
      "(7, 30)         |          18 |   3.21%\n",
      "(24, 48)        |          18 |   3.21%\n",
      "(26, 46)        |          18 |   3.21%\n",
      "\n",
      "Most Common Consecutive Number Pairs:\n",
      "Consecutive Pair | Times Drawn | Probability\n",
      "---------------------------------------------\n",
      "(38, 39)        |          18 |   3.21%\n",
      "(12, 13)        |          17 |   3.04%\n",
      "(18, 19)        |          16 |   2.86%\n",
      "(24, 25)        |          15 |   2.68%\n",
      "(46, 47)        |          15 |   2.68%\n",
      "(1, 2)          |          15 |   2.68%\n",
      "(39, 40)        |          14 |   2.50%\n",
      "(44, 45)        |          14 |   2.50%\n",
      "(5, 6)          |          14 |   2.50%\n",
      "(28, 29)        |          13 |   2.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "def analyze_number_combinations():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('lottery_results.csv')\n",
    "    \n",
    "    # Filter for dates after July 2019 (RNG era)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'] >= '2019-07-01']\n",
    "    \n",
    "    # Create a list of all 7-number combinations from each draw\n",
    "    all_combinations = []\n",
    "    for index, row in df.iterrows():\n",
    "        numbers = [\n",
    "            int(row[f'Main Numbers {i}']) \n",
    "            for i in range(1, 8)\n",
    "        ]\n",
    "        all_combinations.append(tuple(sorted(numbers)))\n",
    "    \n",
    "    # Count frequency of each combination\n",
    "    combination_counts = Counter(all_combinations)\n",
    "    \n",
    "    # Calculate pair frequencies (numbers that appear together)\n",
    "    pair_counts = Counter()\n",
    "    for combo in all_combinations:\n",
    "        # Get all possible pairs from the 7 numbers\n",
    "        pairs = list(combinations(combo, 2))\n",
    "        pair_counts.update(pairs)\n",
    "    \n",
    "    total_draws = len(df)\n",
    "    \n",
    "    print(f\"\\nAnalysis based on {total_draws} draws:\\n\")\n",
    "    \n",
    "    # Most common pairs\n",
    "    print(\"\\nMost Common Pairs of Numbers:\")\n",
    "    print(\"Pair | Times Drawn | Probability\")\n",
    "    print(\"-\" * 35)\n",
    "    for pair, count in pair_counts.most_common(10):\n",
    "        prob = (count / total_draws) * 100\n",
    "        print(f\"{str(pair):15s} | {count:11d} | {prob:6.2f}%\")\n",
    "    \n",
    "    # Analyze consecutive numbers\n",
    "    consecutive_counts = Counter()\n",
    "    for combo in all_combinations:\n",
    "        for i in range(len(combo)-1):\n",
    "            if combo[i+1] - combo[i] == 1:\n",
    "                consecutive_counts.update([(combo[i], combo[i+1])])\n",
    "    \n",
    "    print(\"\\nMost Common Consecutive Number Pairs:\")\n",
    "    print(\"Consecutive Pair | Times Drawn | Probability\")\n",
    "    print(\"-\" * 45)\n",
    "    for pair, count in consecutive_counts.most_common(10):\n",
    "        prob = (count / total_draws) * 100\n",
    "        print(f\"{str(pair):15s} | {count:11d} | {prob:6.2f}%\")\n",
    "\n",
    "analyze_number_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.conda/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in ./.conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in ./.conda/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: tensorflow in ./.conda/lib/python3.11/site-packages (2.18.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./.conda/lib/python3.11/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.conda/lib/python3.11/site-packages (from tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.11/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.conda/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./.conda/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.conda/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./.conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading matplotlib-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading pillow-11.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.3 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas scikit-learn tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lang/max-bot/.conda/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 550.6201 - mae: 22.9426 - val_loss: 177.0773 - val_mae: 12.9454 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.0936 - mae: 9.5083 - val_loss: 6.7306 - val_mae: 1.6793 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2995 - mae: 1.3206 - val_loss: 2.1825 - val_mae: 0.5721 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1783 - mae: 0.5778 - val_loss: 2.1231 - val_mae: 0.5207 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0557 - mae: 0.5213 - val_loss: 2.1141 - val_mae: 0.5123 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0802 - mae: 0.5152 - val_loss: 2.1110 - val_mae: 0.5094 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1080 - mae: 0.5168 - val_loss: 2.1093 - val_mae: 0.5078 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1098 - mae: 0.5188 - val_loss: 2.1081 - val_mae: 0.5066 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1199 - mae: 0.5167 - val_loss: 2.1071 - val_mae: 0.5056 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0761 - mae: 0.5078 - val_loss: 2.1055 - val_mae: 0.5039 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0807 - mae: 0.5040 - val_loss: 2.1050 - val_mae: 0.5033 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0896 - mae: 0.5074 - val_loss: 2.1047 - val_mae: 0.5030 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1132 - mae: 0.5108 - val_loss: 2.1045 - val_mae: 0.5027 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1378 - mae: 0.5141 - val_loss: 2.1043 - val_mae: 0.5025 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0866 - mae: 0.5020 - val_loss: 2.1042 - val_mae: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0691 - mae: 0.5047 - val_loss: 2.1041 - val_mae: 0.5023 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1156 - mae: 0.5089 - val_loss: 2.1041 - val_mae: 0.5022 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0813 - mae: 0.5013 - val_loss: 2.1040 - val_mae: 0.5022 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0882 - mae: 0.5013 - val_loss: 2.1040 - val_mae: 0.5021 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1044 - mae: 0.5055 - val_loss: 2.1039 - val_mae: 0.5021 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0939 - mae: 0.5080 - val_loss: 2.1039 - val_mae: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1250 - mae: 0.5103 - val_loss: 2.1039 - val_mae: 0.5020 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0917 - mae: 0.5001 - val_loss: 2.1039 - val_mae: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0671 - mae: 0.5004 - val_loss: 2.1038 - val_mae: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0908 - mae: 0.5031 - val_loss: 2.1038 - val_mae: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0912 - mae: 0.5048 - val_loss: 2.1038 - val_mae: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0346 - mae: 0.4955 - val_loss: 2.1038 - val_mae: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0732 - mae: 0.5005 - val_loss: 2.1038 - val_mae: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1291 - mae: 0.5112 - val_loss: 2.1037 - val_mae: 0.5018 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1109 - mae: 0.5065 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0761 - mae: 0.5041 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0814 - mae: 0.5024 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0616 - mae: 0.5001 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0638 - mae: 0.5016 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1231 - mae: 0.5115 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0746 - mae: 0.5030 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0878 - mae: 0.5042 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1391 - mae: 0.5110 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0718 - mae: 0.5033 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1263 - mae: 0.5103 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0592 - mae: 0.4988 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1305 - mae: 0.5068 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1053 - mae: 0.5040 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0994 - mae: 0.5055 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0421 - mae: 0.4983 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0867 - mae: 0.5027 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1231 - mae: 0.5055 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0719 - mae: 0.4994 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0534 - mae: 0.4967 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1194 - mae: 0.5076 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0930 - mae: 0.5012 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0532 - mae: 0.4984 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1270 - mae: 0.5112 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0653 - mae: 0.5015 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0854 - mae: 0.5025 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1556 - mae: 0.5101 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0851 - mae: 0.5008 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0654 - mae: 0.4985 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0727 - mae: 0.5034 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0484 - mae: 0.4975 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1267 - mae: 0.5077 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0430 - mae: 0.4955 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0914 - mae: 0.5048 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0980 - mae: 0.5064 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0531 - mae: 0.5007 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0907 - mae: 0.5080 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0801 - mae: 0.5041 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0771 - mae: 0.5008 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0805 - mae: 0.5012 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0931 - mae: 0.5038 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0866 - mae: 0.5009 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0534 - mae: 0.4974 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1213 - mae: 0.5081 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0999 - mae: 0.5048 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0317 - mae: 0.4943 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0702 - mae: 0.5029 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1187 - mae: 0.5039 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1105 - mae: 0.5062 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0826 - mae: 0.5028 - val_loss: 2.1037 - val_mae: 0.5017 - learning_rate: 1.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0349 - mae: 0.4964 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1264 - mae: 0.5085 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0849 - mae: 0.5061 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0773 - mae: 0.5010 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0762 - mae: 0.5028 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0502 - mae: 0.4965 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0913 - mae: 0.5050 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1013 - mae: 0.5095 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0916 - mae: 0.5025 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0890 - mae: 0.5014 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0863 - mae: 0.5061 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0299 - mae: 0.4936 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0655 - mae: 0.5000 - val_loss: 2.1037 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1168 - mae: 0.5067 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1041 - mae: 0.5090 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0960 - mae: 0.5016 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1118 - mae: 0.5046 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1370 - mae: 0.5087 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0495 - mae: 0.4966 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0933 - mae: 0.5025 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0562 - mae: 0.5015 - val_loss: 2.1036 - val_mae: 0.5016 - learning_rate: 1.0000e-04\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x17deae520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "Prediction Analysis:\n",
      "3+ numbers correct: 0 times (0.0%)\n",
      "4+ numbers correct: 0 times (0.0%)\n",
      "5+ numbers correct: 0 times (0.0%)\n",
      "6+ numbers correct: 0 times (0.0%)\n",
      "7+ numbers correct: 0 times (0.0%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Lambda  # Added Lambda here\n",
    "import tensorflow as tf\n",
    "\n",
    "def prepare_lottery_data():\n",
    "    # Read and filter data\n",
    "    df = pd.read_csv('lottery_results.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'] >= '2019-07-01']\n",
    "    \n",
    "    # Create features\n",
    "    X = []\n",
    "    y = []\n",
    "    sequence_length = 5  # Look at previous 5 draws to predict next one\n",
    "    \n",
    "    # Prepare sequences\n",
    "    numbers = []\n",
    "    for index, row in df.iterrows():\n",
    "        draw = [int(row[f'Main Numbers {i}']) for i in range(1, 8)]\n",
    "        numbers.append(draw)\n",
    "    \n",
    "    numbers = np.array(numbers)\n",
    "    \n",
    "    # Create sequences: use previous n draws to predict next draw\n",
    "    for i in range(len(numbers) - sequence_length):\n",
    "        X.append(numbers[i:i+sequence_length])\n",
    "        y.append(numbers[i+sequence_length])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_model_with_better_matching():\n",
    "    def match_focused_loss(y_true, y_pred):\n",
    "        # Round predictions to valid lottery numbers (1-50)\n",
    "        y_pred_rounded = tf.clip_by_value(tf.round(y_pred), 1, 50)\n",
    "        \n",
    "        # Calculate number of matches\n",
    "        exact_matches = tf.reduce_sum(tf.cast(\n",
    "            tf.abs(y_pred_rounded - y_true) < 0.5, \n",
    "            tf.float32\n",
    "        ), axis=1)\n",
    "        \n",
    "        # Base MSE loss\n",
    "        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        \n",
    "        # Add penalty for low matches (instead of subtracting match score)\n",
    "        match_penalty = tf.reduce_mean(7.0 - exact_matches)  # 7 is max possible matches\n",
    "        \n",
    "        return mse + match_penalty * 0.5\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(5, 7)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(7, activation='sigmoid'),  # Sigmoid to constrain output\n",
    "        Lambda(lambda x: x * 49 + 1)  # Scale to 1-50 range\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=match_focused_loss,\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, thresholds=[3, 4, 5, 6, 7]):\n",
    "    \"\"\"Evaluate predictions based on number of correct matches\"\"\"\n",
    "    matches = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        # Round predictions to nearest integer\n",
    "        pred_rounded = np.round(pred).clip(1, 50)\n",
    "        # Count matches\n",
    "        match_count = sum(abs(t - p) < 1 for t, p in zip(true, pred_rounded))\n",
    "        matches.append(match_count)\n",
    "    \n",
    "    # Print statistics for different match thresholds\n",
    "    print(\"\\nPrediction Analysis:\")\n",
    "    for threshold in thresholds:\n",
    "        count = sum(m >= threshold for m in matches)\n",
    "        percentage = (count / len(matches)) * 100\n",
    "        print(f\"{threshold}+ numbers correct: {count} times ({percentage:.1f}%)\")\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def train_with_validation():\n",
    "    X, y = prepare_lottery_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Normalize targets to 0-1 range\n",
    "    y_train = (y_train - 1) / 49\n",
    "    y_test = (y_test - 1) / 49\n",
    "    \n",
    "    model = create_model_with_better_matching()\n",
    "    \n",
    "    # Early stopping with patience\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=0.0001\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = predictions * 49 + 1  # Scale back to 1-50 range\n",
    "    y_test = y_test * 49 + 1\n",
    "    \n",
    "    evaluate_predictions(y_test, predictions)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Run training\n",
    "model, history = train_with_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Analysis:\n",
      "Minimum validation loss: 2.10 at epoch 100\n",
      "Final validation loss: 2.10\n",
      "Final validation MAE: 0.50\n",
      "\n",
      "Overfitting Analysis:\n",
      "Final training loss: 2.09\n",
      "Final validation loss: 2.10\n",
      "Loss difference: 0.01\n",
      "Loss ratio: 1.01\n",
      "\n",
      "Convergence Analysis:\n",
      "Standard deviation of last 5 validation losses: 0.0000\n",
      "Model appears to have converged (stable validation loss)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_training(history):\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model MAE')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze convergence\n",
    "    min_val_loss = min(history.history['val_loss'])\n",
    "    min_val_loss_epoch = history.history['val_loss'].index(min_val_loss)\n",
    "    \n",
    "    print(\"\\nTraining Analysis:\")\n",
    "    print(f\"Minimum validation loss: {min_val_loss:.2f} at epoch {min_val_loss_epoch + 1}\")\n",
    "    print(f\"Final validation loss: {history.history['val_loss'][-1]:.2f}\")\n",
    "    print(f\"Final validation MAE: {history.history['val_mae'][-1]:.2f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    loss_diff = abs(train_loss - val_loss)\n",
    "    loss_ratio = max(train_loss, val_loss) / min(train_loss, val_loss)\n",
    "    \n",
    "    print(\"\\nOverfitting Analysis:\")\n",
    "    print(f\"Final training loss: {train_loss:.2f}\")\n",
    "    print(f\"Final validation loss: {val_loss:.2f}\")\n",
    "    print(f\"Loss difference: {loss_diff:.2f}\")\n",
    "    print(f\"Loss ratio: {loss_ratio:.2f}\")\n",
    "    \n",
    "    if loss_ratio > 1.2:\n",
    "        print(\"Warning: Possible overfitting detected (loss ratio > 1.2)\")\n",
    "    \n",
    "    # Convergence check\n",
    "    last_5_val_loss = history.history['val_loss'][-5:]\n",
    "    val_loss_std = np.std(last_5_val_loss)\n",
    "    print(f\"\\nConvergence Analysis:\")\n",
    "    print(f\"Standard deviation of last 5 validation losses: {val_loss_std:.4f}\")\n",
    "    if val_loss_std < 0.1:\n",
    "        print(\"Model appears to have converged (stable validation loss)\")\n",
    "    else:\n",
    "        print(\"Model might benefit from more training (validation loss still varying)\")\n",
    "\n",
    "# After training the model:\n",
    "analyze_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Analysis (560 draws):\n",
      "Expected frequency per number: 78.4\n",
      "\n",
      "Most common numbers:\n",
      "Number 19:  94 times (deviation: +19.9%)\n",
      "Number 46:  94 times (deviation: +19.9%)\n",
      "Number 32:  90 times (deviation: +14.8%)\n",
      "Number 36:  89 times (deviation: +13.5%)\n",
      "Number  7:  88 times (deviation: +12.2%)\n",
      "Number 26:  88 times (deviation: +12.2%)\n",
      "Number 28:  88 times (deviation: +12.2%)\n",
      "Number 22:  87 times (deviation: +11.0%)\n",
      "Number 38:  87 times (deviation: +11.0%)\n",
      "Number 30:  86 times (deviation: +9.7%)\n",
      "\n",
      "Chi-square statistic: 35.18\n",
      "\n",
      "Least common numbers:\n",
      "Number 20:  66 times (deviation: -15.8%)\n",
      "Number 27:  66 times (deviation: -15.8%)\n",
      "Number 41:  66 times (deviation: -15.8%)\n",
      "Number 10:  68 times (deviation: -13.3%)\n",
      "Number 42:  68 times (deviation: -13.3%)\n",
      "Number  8:  69 times (deviation: -12.0%)\n",
      "Number 49:  69 times (deviation: -12.0%)\n",
      "Number 33:  70 times (deviation: -10.7%)\n",
      "Number 47:  70 times (deviation: -10.7%)\n",
      "Number 43:  71 times (deviation: -9.4%)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_lottery_statistics():\n",
    "    # Read and filter data\n",
    "    df = pd.read_csv('lottery_results.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'] >= '2019-07-01']\n",
    "    \n",
    "    # Analyze number frequencies\n",
    "    all_numbers = []\n",
    "    for i in range(1, 8):\n",
    "        numbers = df[f'Main Numbers {i}'].tolist()\n",
    "        all_numbers.extend(numbers)\n",
    "    \n",
    "    freq = Counter(all_numbers)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_draws = len(df)\n",
    "    expected_freq = total_draws * 7 / 50  # Expected frequency if truly random\n",
    "    \n",
    "    print(f\"\\nStatistical Analysis ({total_draws} draws):\")\n",
    "    print(f\"Expected frequency per number: {expected_freq:.1f}\")\n",
    "    print(\"\\nMost common numbers:\")\n",
    "    for num, count in freq.most_common(10):\n",
    "        deviation = ((count - expected_freq) / expected_freq) * 100\n",
    "        print(f\"Number {num:2d}: {count:3d} times (deviation: {deviation:+.1f}%)\")\n",
    "    \n",
    "    # Chi-square test for randomness\n",
    "    chi_square = sum((count - expected_freq) ** 2 / expected_freq \n",
    "                    for count in freq.values())\n",
    "    print(f\"\\nChi-square statistic: {chi_square:.2f}\")\n",
    "    \n",
    "    # Additional analysis: Least common numbers\n",
    "    print(\"\\nLeast common numbers:\")\n",
    "    for num, count in sorted(freq.items(), key=lambda x: x[1])[:10]:\n",
    "        deviation = ((count - expected_freq) / expected_freq) * 100\n",
    "        print(f\"Number {num:2d}: {count:3d} times (deviation: {deviation:+.1f}%)\")\n",
    "    \n",
    "    return freq\n",
    "\n",
    "# Run statistical analysis\n",
    "frequencies = analyze_lottery_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability Analysis:\n",
      "Total possible combinations: 99,884,400\n",
      "Base probability of jackpot: 1 in 99,884,400\n",
      "\n",
      "Probability by Prize Division:\n",
      "Division 5: 1 in 23.12\n",
      "Division 4: 1 in 231.25\n",
      "Division 3: 1 in 5267.33\n",
      "Division 2: 1 in 331841.86\n",
      "Division 1 (Jackpot): 1 in 99884400.00\n",
      "\n",
      "Generating optimal coverage for 100 tickets...\n",
      "Number coverage: 50/50 numbers used\n",
      "Average gap between numbers: 1.69\n",
      "\n",
      "Generated 5 balanced tickets after 10 attempts\n",
      "\n",
      "Ticket Analysis:\n",
      "Average high/low ratio: 0.54\n",
      "Average even/odd ratio: 0.49\n",
      "\n",
      "Example Optimal Tickets:\n",
      "Ticket 1: [1, 2, 3, 4, 5, 6, 7]\n",
      "Ticket 2: [2, 3, 4, 5, 6, 8, 50]\n",
      "Ticket 3: [3, 4, 5, 6, 7, 8, 9]\n",
      "Ticket 4: [4, 5, 6, 7, 8, 9, 10]\n",
      "Ticket 5: [5, 6, 7, 8, 9, 11, 36]\n",
      "\n",
      "Example Balanced Tickets:\n",
      "Ticket 1: [3, 13, 15, 22, 33, 45, 50]\n",
      "Ticket 2: [1, 2, 16, 21, 26, 35, 37]\n",
      "Ticket 3: [1, 12, 21, 26, 30, 43, 48]\n",
      "Ticket 4: [11, 14, 27, 34, 41, 48, 49]\n",
      "Ticket 5: [7, 13, 24, 26, 36, 38, 40]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "def calculate_optimal_combinations():\n",
    "    total_numbers = 50\n",
    "    numbers_to_pick = 7\n",
    "    \n",
    "    # Base probability of winning jackpot\n",
    "    jackpot_combinations = math.comb(total_numbers, numbers_to_pick)\n",
    "    base_probability = 1 / jackpot_combinations\n",
    "    print(f\"\\nProbability Analysis:\")\n",
    "    print(f\"Total possible combinations: {jackpot_combinations:,}\")\n",
    "    print(f\"Base probability of jackpot: 1 in {jackpot_combinations:,}\")\n",
    "    \n",
    "    # Probability and prize tiers for smaller wins\n",
    "    prize_tiers = {\n",
    "        7: \"Division 1 (Jackpot)\",\n",
    "        6: \"Division 2\",\n",
    "        5: \"Division 3\",\n",
    "        4: \"Division 4\",\n",
    "        3: \"Division 5\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nProbability by Prize Division:\")\n",
    "    for matches in range(3, 8):\n",
    "        ways_to_match = math.comb(7, matches) * math.comb(43, 7-matches)\n",
    "        probability = ways_to_match / math.comb(50, 7)\n",
    "        print(f\"{prize_tiers[matches]}: 1 in {1/probability:.2f}\")\n",
    "\n",
    "def generate_optimal_coverage(budget, ticket_cost=1):\n",
    "    num_tickets = budget // ticket_cost\n",
    "    print(f\"\\nGenerating optimal coverage for {num_tickets} tickets...\")\n",
    "    \n",
    "    combinations = []\n",
    "    base_numbers = list(range(1, 51))\n",
    "    \n",
    "    for i in range(num_tickets):\n",
    "        # Use systematic spacing with some randomization\n",
    "        start_idx = i % 44  # 50 - 7 + 1\n",
    "        base_combo = base_numbers[start_idx:start_idx+7]\n",
    "        \n",
    "        # Add some randomization to avoid pure sequential numbers\n",
    "        if random.random() < 0.3:  # 30% chance to modify\n",
    "            random_idx = random.randint(0, 6)\n",
    "            available = set(range(1, 51)) - set(base_combo)\n",
    "            base_combo[random_idx] = random.choice(list(available))\n",
    "        \n",
    "        combinations.append(sorted(base_combo))\n",
    "    \n",
    "    # Analyze coverage\n",
    "    numbers_used = set()\n",
    "    for combo in combinations:\n",
    "        numbers_used.update(combo)\n",
    "    \n",
    "    print(f\"Number coverage: {len(numbers_used)}/50 numbers used\")\n",
    "    print(f\"Average gap between numbers: {calculate_average_gap(combinations):.2f}\")\n",
    "    \n",
    "    return combinations\n",
    "\n",
    "def generate_balanced_tickets(num_tickets=10):\n",
    "    balanced_tickets = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_tickets * 100  # Prevent infinite loops\n",
    "    \n",
    "    def is_balanced(combination):\n",
    "        high_count = sum(1 for x in combination if x > 25)\n",
    "        even_count = sum(1 for x in combination if x % 2 == 0)\n",
    "        gaps = [combination[i+1] - combination[i] for i in range(len(combination)-1)]\n",
    "        \n",
    "        return (2 <= high_count <= 5 and  # Balance high/low\n",
    "                2 <= even_count <= 5 and  # Balance even/odd\n",
    "                max(gaps) <= 15)          # Avoid large gaps\n",
    "    \n",
    "    while len(balanced_tickets) < num_tickets and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        # Generate random combination\n",
    "        combo = sorted(random.sample(range(1, 51), 7))\n",
    "        \n",
    "        if is_balanced(combo) and combo not in balanced_tickets:\n",
    "            balanced_tickets.append(combo)\n",
    "    \n",
    "    print(f\"\\nGenerated {len(balanced_tickets)} balanced tickets after {attempts} attempts\")\n",
    "    analyze_tickets(balanced_tickets)\n",
    "    \n",
    "    return balanced_tickets\n",
    "\n",
    "def calculate_average_gap(combinations):\n",
    "    total_gaps = 0\n",
    "    gap_count = 0\n",
    "    \n",
    "    for combo in combinations:\n",
    "        for i in range(len(combo)-1):\n",
    "            total_gaps += combo[i+1] - combo[i]\n",
    "            gap_count += 1\n",
    "    \n",
    "    return total_gaps / gap_count if gap_count > 0 else 0\n",
    "\n",
    "def analyze_tickets(tickets):\n",
    "    \"\"\"Analyze the characteristics of generated tickets\"\"\"\n",
    "    high_low_ratios = []\n",
    "    even_odd_ratios = []\n",
    "    \n",
    "    for combo in tickets:\n",
    "        high_count = sum(1 for x in combo if x > 25)\n",
    "        even_count = sum(1 for x in combo if x % 2 == 0)\n",
    "        \n",
    "        high_low_ratios.append(high_count / 7)\n",
    "        even_odd_ratios.append(even_count / 7)\n",
    "    \n",
    "    print(\"\\nTicket Analysis:\")\n",
    "    print(f\"Average high/low ratio: {sum(high_low_ratios)/len(high_low_ratios):.2f}\")\n",
    "    print(f\"Average even/odd ratio: {sum(even_odd_ratios)/len(even_odd_ratios):.2f}\")\n",
    "\n",
    "# Example usage\n",
    "calculate_optimal_combinations()\n",
    "optimal_tickets = generate_optimal_coverage(budget=100)\n",
    "balanced_tickets = generate_balanced_tickets(num_tickets=5)\n",
    "\n",
    "# Print example tickets\n",
    "print(\"\\nExample Optimal Tickets:\")\n",
    "for i, ticket in enumerate(optimal_tickets[:5], 1):\n",
    "    print(f\"Ticket {i}: {ticket}\")\n",
    "\n",
    "print(\"\\nExample Balanced Tickets:\")\n",
    "for i, ticket in enumerate(balanced_tickets[:5], 1):\n",
    "    print(f\"Ticket {i}: {ticket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Analysis (560 draws):\n",
      "Expected frequency per number: 78.4\n",
      "\n",
      "Most common numbers:\n",
      "Number 19:  94 times (deviation: +19.9%)\n",
      "Number 46:  94 times (deviation: +19.9%)\n",
      "Number 32:  90 times (deviation: +14.8%)\n",
      "Number 36:  89 times (deviation: +13.5%)\n",
      "Number  7:  88 times (deviation: +12.2%)\n",
      "Number 26:  88 times (deviation: +12.2%)\n",
      "Number 28:  88 times (deviation: +12.2%)\n",
      "Number 22:  87 times (deviation: +11.0%)\n",
      "Number 38:  87 times (deviation: +11.0%)\n",
      "Number 30:  86 times (deviation: +9.7%)\n",
      "\n",
      "Chi-square statistic: 35.18\n",
      "\n",
      "Least common numbers:\n",
      "Number 20:  66 times (deviation: -15.8%)\n",
      "Number 27:  66 times (deviation: -15.8%)\n",
      "Number 41:  66 times (deviation: -15.8%)\n",
      "Number 10:  68 times (deviation: -13.3%)\n",
      "Number 42:  68 times (deviation: -13.3%)\n",
      "Number  8:  69 times (deviation: -12.0%)\n",
      "Number 49:  69 times (deviation: -12.0%)\n",
      "Number 33:  70 times (deviation: -10.7%)\n",
      "Number 47:  70 times (deviation: -10.7%)\n",
      "Number 43:  71 times (deviation: -9.4%)\n",
      "\n",
      "Generated 10 smart tickets:\n",
      "\n",
      "Ticket Analysis:\n",
      "Coverage of top 10 historical numbers: 7/10\n",
      "Average high/low ratio: 0.53\n",
      "Average even/odd ratio: 0.61\n",
      "\n",
      "Example Tickets:\n",
      "Ticket 1: [4, 9, 11, 14, 30, 34, 43] (Contains 1 frequent numbers)\n",
      "Ticket 2: [1, 7, 10, 30, 46, 47, 50] (Contains 3 frequent numbers)\n",
      "Ticket 3: [4, 5, 18, 20, 26, 44, 50] (Contains 1 frequent numbers)\n",
      "Ticket 4: [2, 15, 26, 27, 42, 44, 46] (Contains 2 frequent numbers)\n",
      "Ticket 5: [8, 10, 13, 14, 17, 20, 44] (Contains 0 frequent numbers)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def generate_smart_tickets(num_tickets=10, historical_weight=0.3):\n",
    "    \"\"\"\n",
    "    Generate tickets using both historical frequencies and balanced distribution\n",
    "    historical_weight: 0-1 value determining how much to factor in historical frequencies\n",
    "    \"\"\"\n",
    "    # Get historical frequencies\n",
    "    freq_data = analyze_lottery_statistics()  # Using your existing function\n",
    "    \n",
    "    # Calculate probability weights for each number\n",
    "    total_draws = sum(freq_data.values())\n",
    "    weights = {num: count/total_draws for num, count in freq_data.items()}\n",
    "    \n",
    "    def smart_number_selection():\n",
    "        selected = []\n",
    "        remaining = list(range(1, 51))\n",
    "        \n",
    "        while len(selected) < 7:\n",
    "            # Calculate combined score for each remaining number\n",
    "            scores = {}\n",
    "            for num in remaining:\n",
    "                # Historical frequency score\n",
    "                freq_score = weights[num]\n",
    "                \n",
    "                # Balance score (if we already have some numbers)\n",
    "                if selected:\n",
    "                    high_count = sum(1 for x in selected if x > 25)\n",
    "                    even_count = sum(1 for x in selected if x % 2 == 0)\n",
    "                    \n",
    "                    # Calculate balance factors\n",
    "                    high_low_balance = 1.0 if ((num > 25 and high_count < 4) or \n",
    "                                             (num <= 25 and high_count >= 4)) else 0.5\n",
    "                    even_odd_balance = 1.0 if ((num % 2 == 0 and even_count < 4) or \n",
    "                                             (num % 2 != 0 and even_count >= 4)) else 0.5\n",
    "                    \n",
    "                    # Gap score (prefer numbers with reasonable gaps)\n",
    "                    if len(selected) > 0:\n",
    "                        closest_gap = min(abs(num - x) for x in selected)\n",
    "                        gap_score = 1.0 if 2 <= closest_gap <= 8 else 0.5\n",
    "                    else:\n",
    "                        gap_score = 1.0\n",
    "                    \n",
    "                    balance_score = (high_low_balance + even_odd_balance + gap_score) / 3\n",
    "                else:\n",
    "                    balance_score = 1.0\n",
    "                \n",
    "                # Combine scores\n",
    "                scores[num] = (freq_score * historical_weight + \n",
    "                             balance_score * (1 - historical_weight))\n",
    "            \n",
    "            # Select number based on scores\n",
    "            chosen = random.choices(\n",
    "                population=list(scores.keys()),\n",
    "                weights=list(scores.values()),\n",
    "                k=1\n",
    "            )[0]\n",
    "            \n",
    "            selected.append(chosen)\n",
    "            remaining.remove(chosen)\n",
    "        \n",
    "        return sorted(selected)\n",
    "    \n",
    "    # Generate tickets\n",
    "    tickets = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_tickets * 100\n",
    "    \n",
    "    while len(tickets) < num_tickets and attempts < max_attempts:\n",
    "        ticket = smart_number_selection()\n",
    "        if ticket not in tickets:  # Avoid duplicates\n",
    "            tickets.append(ticket)\n",
    "        attempts += 1\n",
    "    \n",
    "    # Analyze generated tickets\n",
    "    print(f\"\\nGenerated {len(tickets)} smart tickets:\")\n",
    "    analyze_smart_tickets(tickets, freq_data)\n",
    "    \n",
    "    return tickets\n",
    "\n",
    "def analyze_smart_tickets(tickets, freq_data):\n",
    "    \"\"\"Analyze the characteristics of generated smart tickets\"\"\"\n",
    "    print(\"\\nTicket Analysis:\")\n",
    "    \n",
    "    # Frequency analysis\n",
    "    used_numbers = []\n",
    "    for ticket in tickets:\n",
    "        used_numbers.extend(ticket)\n",
    "    number_freq = Counter(used_numbers)\n",
    "    \n",
    "    # Most used high-frequency numbers\n",
    "    most_common = freq_data.most_common(10)\n",
    "    high_freq_coverage = sum(1 for num, _ in most_common if num in number_freq)\n",
    "    print(f\"Coverage of top 10 historical numbers: {high_freq_coverage}/10\")\n",
    "    \n",
    "    # Balance statistics\n",
    "    high_low_ratios = []\n",
    "    even_odd_ratios = []\n",
    "    \n",
    "    for ticket in tickets:\n",
    "        high_count = sum(1 for x in ticket if x > 25)\n",
    "        even_count = sum(1 for x in ticket if x % 2 == 0)\n",
    "        \n",
    "        high_low_ratios.append(high_count / 7)\n",
    "        even_odd_ratios.append(even_count / 7)\n",
    "    \n",
    "    print(f\"Average high/low ratio: {sum(high_low_ratios)/len(high_low_ratios):.2f}\")\n",
    "    print(f\"Average even/odd ratio: {sum(even_odd_ratios)/len(even_odd_ratios):.2f}\")\n",
    "    \n",
    "    # Print example tickets\n",
    "    print(\"\\nExample Tickets:\")\n",
    "    for i, ticket in enumerate(tickets[:5], 1):\n",
    "        high_freq_nums = sum(1 for num in ticket if num in [n for n, _ in most_common])\n",
    "        print(f\"Ticket {i}: {ticket} (Contains {high_freq_nums} frequent numbers)\")\n",
    "\n",
    "# Generate some smart tickets\n",
    "smart_tickets = generate_smart_tickets(num_tickets=10, historical_weight=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 1: More Random\n",
      "\n",
      "Statistical Analysis (560 draws):\n",
      "Expected frequency per number: 78.4\n",
      "\n",
      "Most common numbers:\n",
      "Number 19:  94 times (deviation: +19.9%)\n",
      "Number 46:  94 times (deviation: +19.9%)\n",
      "Number 32:  90 times (deviation: +14.8%)\n",
      "Number 36:  89 times (deviation: +13.5%)\n",
      "Number  7:  88 times (deviation: +12.2%)\n",
      "Number 26:  88 times (deviation: +12.2%)\n",
      "Number 28:  88 times (deviation: +12.2%)\n",
      "Number 22:  87 times (deviation: +11.0%)\n",
      "Number 38:  87 times (deviation: +11.0%)\n",
      "Number 30:  86 times (deviation: +9.7%)\n",
      "\n",
      "Chi-square statistic: 35.18\n",
      "\n",
      "Least common numbers:\n",
      "Number 20:  66 times (deviation: -15.8%)\n",
      "Number 27:  66 times (deviation: -15.8%)\n",
      "Number 41:  66 times (deviation: -15.8%)\n",
      "Number 10:  68 times (deviation: -13.3%)\n",
      "Number 42:  68 times (deviation: -13.3%)\n",
      "Number  8:  69 times (deviation: -12.0%)\n",
      "Number 49:  69 times (deviation: -12.0%)\n",
      "Number 33:  70 times (deviation: -10.7%)\n",
      "Number 47:  70 times (deviation: -10.7%)\n",
      "Number 43:  71 times (deviation: -9.4%)\n",
      "\n",
      "Generated 5 hybrid tickets:\n",
      "Randomness factor: 0.70\n",
      "Historical weight: 0.30\n",
      "\n",
      "Ticket Analysis:\n",
      "\n",
      "Coverage Statistics:\n",
      "Top 10 historical numbers coverage: 7/10\n",
      "Number range coverage: 29/50\n",
      "\n",
      "Balance Metrics:\n",
      "Average high/low ratio: 0.51\n",
      "Average even/odd ratio: 0.60\n",
      "Average gap between numbers: 5.27\n",
      "\n",
      "Example Tickets:\n",
      "Ticket 1: [9, 19, 27, 30, 31, 42, 43]\n",
      "Contains 2 frequent numbers\n",
      "High/Low: 5/2\n",
      "Even/Odd: 2/5\n",
      "\n",
      "Ticket 2: [4, 15, 16, 19, 23, 30, 32]\n",
      "Contains 3 frequent numbers\n",
      "High/Low: 2/5\n",
      "Even/Odd: 4/3\n",
      "\n",
      "Ticket 3: [8, 14, 33, 34, 44, 45, 46]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 5/2\n",
      "Even/Odd: 5/2\n",
      "\n",
      "Ticket 4: [17, 19, 20, 22, 24, 28, 35]\n",
      "Contains 3 frequent numbers\n",
      "High/Low: 2/5\n",
      "Even/Odd: 4/3\n",
      "\n",
      "Ticket 5: [2, 7, 18, 28, 34, 40, 42]\n",
      "Contains 2 frequent numbers\n",
      "High/Low: 4/3\n",
      "Even/Odd: 6/1\n",
      "\n",
      "\n",
      "Strategy 2: More Balanced\n",
      "\n",
      "Statistical Analysis (560 draws):\n",
      "Expected frequency per number: 78.4\n",
      "\n",
      "Most common numbers:\n",
      "Number 19:  94 times (deviation: +19.9%)\n",
      "Number 46:  94 times (deviation: +19.9%)\n",
      "Number 32:  90 times (deviation: +14.8%)\n",
      "Number 36:  89 times (deviation: +13.5%)\n",
      "Number  7:  88 times (deviation: +12.2%)\n",
      "Number 26:  88 times (deviation: +12.2%)\n",
      "Number 28:  88 times (deviation: +12.2%)\n",
      "Number 22:  87 times (deviation: +11.0%)\n",
      "Number 38:  87 times (deviation: +11.0%)\n",
      "Number 30:  86 times (deviation: +9.7%)\n",
      "\n",
      "Chi-square statistic: 35.18\n",
      "\n",
      "Least common numbers:\n",
      "Number 20:  66 times (deviation: -15.8%)\n",
      "Number 27:  66 times (deviation: -15.8%)\n",
      "Number 41:  66 times (deviation: -15.8%)\n",
      "Number 10:  68 times (deviation: -13.3%)\n",
      "Number 42:  68 times (deviation: -13.3%)\n",
      "Number  8:  69 times (deviation: -12.0%)\n",
      "Number 49:  69 times (deviation: -12.0%)\n",
      "Number 33:  70 times (deviation: -10.7%)\n",
      "Number 47:  70 times (deviation: -10.7%)\n",
      "Number 43:  71 times (deviation: -9.4%)\n",
      "\n",
      "Generated 5 hybrid tickets:\n",
      "Randomness factor: 0.30\n",
      "Historical weight: 0.70\n",
      "\n",
      "Ticket Analysis:\n",
      "\n",
      "Coverage Statistics:\n",
      "Top 10 historical numbers coverage: 6/10\n",
      "Number range coverage: 25/50\n",
      "\n",
      "Balance Metrics:\n",
      "Average high/low ratio: 0.57\n",
      "Average even/odd ratio: 0.40\n",
      "Average gap between numbers: 6.40\n",
      "\n",
      "Example Tickets:\n",
      "Ticket 1: [4, 18, 27, 35, 36, 41, 44]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 5/2\n",
      "Even/Odd: 4/3\n",
      "\n",
      "Ticket 2: [7, 11, 21, 29, 36, 40, 50]\n",
      "Contains 2 frequent numbers\n",
      "High/Low: 4/3\n",
      "Even/Odd: 3/4\n",
      "\n",
      "Ticket 3: [7, 17, 23, 35, 39, 41, 49]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 4/3\n",
      "Even/Odd: 0/7\n",
      "\n",
      "Ticket 4: [7, 11, 18, 21, 22, 31, 45]\n",
      "Contains 2 frequent numbers\n",
      "High/Low: 2/5\n",
      "Even/Odd: 2/5\n",
      "\n",
      "Ticket 5: [18, 23, 28, 30, 42, 46, 47]\n",
      "Contains 3 frequent numbers\n",
      "High/Low: 5/2\n",
      "Even/Odd: 5/2\n",
      "\n",
      "\n",
      "Strategy 3: Equal Mix\n",
      "\n",
      "Statistical Analysis (560 draws):\n",
      "Expected frequency per number: 78.4\n",
      "\n",
      "Most common numbers:\n",
      "Number 19:  94 times (deviation: +19.9%)\n",
      "Number 46:  94 times (deviation: +19.9%)\n",
      "Number 32:  90 times (deviation: +14.8%)\n",
      "Number 36:  89 times (deviation: +13.5%)\n",
      "Number  7:  88 times (deviation: +12.2%)\n",
      "Number 26:  88 times (deviation: +12.2%)\n",
      "Number 28:  88 times (deviation: +12.2%)\n",
      "Number 22:  87 times (deviation: +11.0%)\n",
      "Number 38:  87 times (deviation: +11.0%)\n",
      "Number 30:  86 times (deviation: +9.7%)\n",
      "\n",
      "Chi-square statistic: 35.18\n",
      "\n",
      "Least common numbers:\n",
      "Number 20:  66 times (deviation: -15.8%)\n",
      "Number 27:  66 times (deviation: -15.8%)\n",
      "Number 41:  66 times (deviation: -15.8%)\n",
      "Number 10:  68 times (deviation: -13.3%)\n",
      "Number 42:  68 times (deviation: -13.3%)\n",
      "Number  8:  69 times (deviation: -12.0%)\n",
      "Number 49:  69 times (deviation: -12.0%)\n",
      "Number 33:  70 times (deviation: -10.7%)\n",
      "Number 47:  70 times (deviation: -10.7%)\n",
      "Number 43:  71 times (deviation: -9.4%)\n",
      "\n",
      "Generated 5 hybrid tickets:\n",
      "Randomness factor: 0.50\n",
      "Historical weight: 0.50\n",
      "\n",
      "Ticket Analysis:\n",
      "\n",
      "Coverage Statistics:\n",
      "Top 10 historical numbers coverage: 5/10\n",
      "Number range coverage: 28/50\n",
      "\n",
      "Balance Metrics:\n",
      "Average high/low ratio: 0.51\n",
      "Average even/odd ratio: 0.57\n",
      "Average gap between numbers: 6.57\n",
      "\n",
      "Example Tickets:\n",
      "Ticket 1: [6, 7, 12, 17, 24, 44, 50]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 2/5\n",
      "Even/Odd: 5/2\n",
      "\n",
      "Ticket 2: [7, 14, 20, 28, 30, 36, 42]\n",
      "Contains 4 frequent numbers\n",
      "High/Low: 4/3\n",
      "Even/Odd: 6/1\n",
      "\n",
      "Ticket 3: [4, 13, 30, 34, 43, 45, 48]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 5/2\n",
      "Even/Odd: 4/3\n",
      "\n",
      "Ticket 4: [10, 15, 19, 37, 41, 45, 48]\n",
      "Contains 1 frequent numbers\n",
      "High/Low: 4/3\n",
      "Even/Odd: 2/5\n",
      "\n",
      "Ticket 5: [1, 10, 18, 21, 27, 34, 37]\n",
      "Contains 0 frequent numbers\n",
      "High/Low: 3/4\n",
      "Even/Odd: 3/4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def generate_hybrid_tickets(num_tickets=10, randomness_factor=0.3, historical_weight=0.4):\n",
    "    \"\"\"\n",
    "    Generate lottery tickets using a hybrid approach combining random and smart selection\n",
    "    \n",
    "    Parameters:\n",
    "    - num_tickets: Number of tickets to generate\n",
    "    - randomness_factor: 0-1, higher means more pure random tickets\n",
    "    - historical_weight: 0-1, influence of historical frequencies in smart selection\n",
    "    \"\"\"\n",
    "    tickets = []\n",
    "    freq_data = analyze_lottery_statistics()  # Get historical data\n",
    "    \n",
    "    def generate_smart_ticket():\n",
    "        selected = []\n",
    "        remaining = list(range(1, 51))\n",
    "        total_draws = sum(freq_data.values())\n",
    "        weights = {num: count/total_draws for num, count in freq_data.items()}\n",
    "        \n",
    "        while len(selected) < 7:\n",
    "            scores = {}\n",
    "            for num in remaining:\n",
    "                # Historical frequency score\n",
    "                freq_score = weights.get(num, 0)\n",
    "                \n",
    "                # Balance factors\n",
    "                if selected:\n",
    "                    high_count = sum(1 for x in selected if x > 25)\n",
    "                    even_count = sum(1 for x in selected if x % 2 == 0)\n",
    "                    \n",
    "                    # Calculate various balance scores\n",
    "                    high_low_balance = 1.0 if ((num > 25 and high_count < 4) or \n",
    "                                             (num <= 25 and high_count >= 4)) else 0.5\n",
    "                    even_odd_balance = 1.0 if ((num % 2 == 0 and even_count < 4) or \n",
    "                                             (num % 2 != 0 and even_count >= 4)) else 0.5\n",
    "                    \n",
    "                    # Gap analysis\n",
    "                    closest_gap = min(abs(num - x) for x in selected)\n",
    "                    gap_score = 1.0 if 2 <= closest_gap <= 8 else 0.5\n",
    "                    \n",
    "                    balance_score = (high_low_balance + even_odd_balance + gap_score) / 3\n",
    "                else:\n",
    "                    balance_score = 1.0\n",
    "                \n",
    "                # Combine scores with weights\n",
    "                scores[num] = (freq_score * historical_weight + \n",
    "                             balance_score * (1 - historical_weight))\n",
    "            \n",
    "            # Select number based on weighted scores\n",
    "            chosen = random.choices(\n",
    "                population=list(scores.keys()),\n",
    "                weights=list(scores.values()),\n",
    "                k=1\n",
    "            )[0]\n",
    "            \n",
    "            selected.append(chosen)\n",
    "            remaining.remove(chosen)\n",
    "        \n",
    "        return sorted(selected)\n",
    "    \n",
    "    # Generate tickets using hybrid approach\n",
    "    attempts = 0\n",
    "    max_attempts = num_tickets * 100\n",
    "    \n",
    "    while len(tickets) < num_tickets and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        if random.random() < randomness_factor:\n",
    "            # Pure random selection\n",
    "            ticket = sorted(random.sample(range(1, 51), 7))\n",
    "        else:\n",
    "            # Smart balanced selection\n",
    "            ticket = generate_smart_ticket()\n",
    "        \n",
    "        if ticket not in tickets:  # Avoid duplicates\n",
    "            tickets.append(ticket)\n",
    "    \n",
    "    # Analyze and display results\n",
    "    print(f\"\\nGenerated {len(tickets)} hybrid tickets:\")\n",
    "    print(f\"Randomness factor: {randomness_factor:.2f}\")\n",
    "    print(f\"Historical weight: {historical_weight:.2f}\")\n",
    "    analyze_hybrid_tickets(tickets, freq_data)\n",
    "    \n",
    "    return tickets\n",
    "\n",
    "def analyze_hybrid_tickets(tickets, freq_data):\n",
    "    \"\"\"Detailed analysis of generated tickets\"\"\"\n",
    "    print(\"\\nTicket Analysis:\")\n",
    "    \n",
    "    # Frequency analysis\n",
    "    used_numbers = []\n",
    "    for ticket in tickets:\n",
    "        used_numbers.extend(ticket)\n",
    "    number_freq = Counter(used_numbers)\n",
    "    \n",
    "    # Coverage analysis\n",
    "    most_common_hist = freq_data.most_common(10)\n",
    "    high_freq_coverage = sum(1 for num, _ in most_common_hist if num in number_freq)\n",
    "    \n",
    "    # Statistical measures\n",
    "    high_low_ratios = []\n",
    "    even_odd_ratios = []\n",
    "    gaps = []\n",
    "    \n",
    "    for ticket in tickets:\n",
    "        high_count = sum(1 for x in ticket if x > 25)\n",
    "        even_count = sum(1 for x in ticket if x % 2 == 0)\n",
    "        \n",
    "        high_low_ratios.append(high_count / 7)\n",
    "        even_odd_ratios.append(even_count / 7)\n",
    "        \n",
    "        # Calculate gaps\n",
    "        for i in range(len(ticket)-1):\n",
    "            gaps.append(ticket[i+1] - ticket[i])\n",
    "    \n",
    "    # Print analysis\n",
    "    print(f\"\\nCoverage Statistics:\")\n",
    "    print(f\"Top 10 historical numbers coverage: {high_freq_coverage}/10\")\n",
    "    print(f\"Number range coverage: {len(set(used_numbers))}/50\")\n",
    "    \n",
    "    print(f\"\\nBalance Metrics:\")\n",
    "    print(f\"Average high/low ratio: {sum(high_low_ratios)/len(high_low_ratios):.2f}\")\n",
    "    print(f\"Average even/odd ratio: {sum(even_odd_ratios)/len(even_odd_ratios):.2f}\")\n",
    "    print(f\"Average gap between numbers: {sum(gaps)/len(gaps):.2f}\")\n",
    "    \n",
    "    # Print example tickets with analysis\n",
    "    print(\"\\nExample Tickets:\")\n",
    "    for i, ticket in enumerate(tickets[:5], 1):\n",
    "        high_freq_nums = sum(1 for num in ticket if num in [n for n, _ in most_common_hist])\n",
    "        print(f\"Ticket {i}: {ticket}\")\n",
    "        print(f\"Contains {high_freq_nums} frequent numbers\")\n",
    "        print(f\"High/Low: {sum(1 for x in ticket if x > 25)}/{sum(1 for x in ticket if x <= 25)}\")\n",
    "        print(f\"Even/Odd: {sum(1 for x in ticket if x % 2 == 0)}/{sum(1 for x in ticket if x % 2 != 0)}\")\n",
    "        print()\n",
    "\n",
    "# Let's try different strategies\n",
    "print(\"Strategy 1: More Random\")\n",
    "random_heavy = generate_hybrid_tickets(num_tickets=5, randomness_factor=0.7, historical_weight=0.3)\n",
    "\n",
    "print(\"\\nStrategy 2: More Balanced\")\n",
    "balanced_heavy = generate_hybrid_tickets(num_tickets=5, randomness_factor=0.3, historical_weight=0.7)\n",
    "\n",
    "print(\"\\nStrategy 3: Equal Mix\")\n",
    "balanced_mix = generate_hybrid_tickets(num_tickets=5, randomness_factor=0.5, historical_weight=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
